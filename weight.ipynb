{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0251bd94",
   "metadata": {},
   "source": [
    "# Weight tracking, analysis and forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf3ecc0",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bce779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87bcc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Python = {sys.version}')\n",
    "print(f'Numpy = {np.__version__}')\n",
    "print(f'Tensorflow = {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b7d759",
   "metadata": {},
   "source": [
    "# Extraction data brute des CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11665983",
   "metadata": {},
   "source": [
    "### Traite deux fichiers :\n",
    "\n",
    "=> un fichier \"data_BEN.zip\" avec les datas issus de HealthMate :\n",
    "  - masse totale\n",
    "  - masse grasse\n",
    "  - plusieurs pesées à la suite (5 mini) avec le même protocole (matin a jeun après toilettes) \n",
    " \n",
    "=> un fichier \"Suivi_Poids.csv\" avec les datas rentrées à la main, et notamment les données d'exercice : \n",
    "  - masse totale, masse grasse (moyennes des données balance calculées et rentrées à la main)\n",
    "  - données MyFitnessPal : calories in, macros (glucides, lipides, proteines)\n",
    "  - données exercice issues des enregistrements ceinture Polar (calories_exercies, calories_cardio, calories_muscu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RACINE = os.getcwd() + '/'\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b50254",
   "metadata": {},
   "source": [
    "### Extraction fichier HealthMate : données quotidiennes multiples, dans weight.csv dans l'archive Zip 'data_BEN.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1b5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIPFILE_NAME = RACINE + 'data_BEN.zip'\n",
    "WEIGHT_FILE_PATH = RACINE + 'tmp'\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(ZIPFILE_NAME, 'r') as fichier_zip:\n",
    "    print(f'Extraction fichier Zip Healthmate dans {WEIGHT_FILE_PATH}...')\n",
    "    fichier_zip.extractall(path = WEIGHT_FILE_PATH)\n",
    "    print(f'... Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b6647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrait_data(filename, \n",
    "                 champs,\n",
    "                 skip=2,\n",
    "                 delimiter=','):\n",
    "    \"\"\"\n",
    "    Fonction helper qui lit le fichier csv,\n",
    "    et retourne une liste de dictionnaires,\n",
    "    chaque dictionnaire correspondant à une ligne \n",
    "    (cad une mesure quotidienne) du fichier.\n",
    "    \n",
    "    NB : les deux premières lignes sont ignorées\n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        fichier = csv.DictReader(csvfile, fieldnames=champs, delimiter=delimiter)\n",
    "        for i in range(skip):  # passe <skip> lignes au début du fichier\n",
    "            next(fichier)\n",
    "        for row in fichier:\n",
    "            data.append(row)\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f078df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_FILE_CSV_NAME = WEIGHT_FILE_PATH + '/weight.csv'\n",
    "CHAMPS = ['date', 'MT', 'MG']\n",
    "\n",
    "data_brute = extrait_data(WEIGHT_FILE_CSV_NAME, CHAMPS, skip=1, delimiter=',')  # récupère une liste de dictionnaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703c1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6458272",
   "metadata": {},
   "source": [
    "### Extraction données complètes par jour avec calories, macros, etc. depuis 'Suivi_Poids.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0fac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_CALS_EX_CSV_NAME = RACINE + \"Suivi_Poids.csv\"\n",
    "CHAMPS = ['date', 'Masse Totale', 'Masse Grasse', 'Calories in', 'Glucides', 'Lipides', 'Proteines', 'Calories Exercice Brut', 'C_Ex_Cardio', 'C_Ex_Strength','Verif']\n",
    "# NB : CHAMPS doit impérativement contenir un champ 'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04627461",
   "metadata": {},
   "outputs": [],
   "source": [
    "poids_cal_exos = extrait_data(FILE_CALS_EX_CSV_NAME, CHAMPS, skip=2, delimiter=';')  # récupère une liste de dictionnaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a1682",
   "metadata": {},
   "outputs": [],
   "source": [
    "poids_cal_exos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81919f8c",
   "metadata": {},
   "source": [
    "**0- Fonctions helper pour conversions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f3734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_to_date_str(date_string : str) -> datetime.date:\n",
    "    \"\"\"\n",
    "    fonction qui convertit les string sorties de l'extraction en date,\n",
    "    au format \"YY-month_name-day\",\n",
    "    retourne un objet date de la library datetime.\n",
    "    \n",
    "    Permet de faire des calculs sur les dates ensuite.\n",
    "    \"\"\"\n",
    "    \n",
    "    dict_mois = { 'août' : 8, \n",
    "                 'sept.' : 9,\n",
    "                 'oct.' : 10,\n",
    "                 'nov.' : 11,\n",
    "                 'déc.' : 12,\n",
    "                 'janv.' : 1,\n",
    "                 'févr.' : 2,\n",
    "                 'mars' : 3,\n",
    "                 'avr.' : 4,\n",
    "                 'mai' : 5,\n",
    "                 'juin' : 6,\n",
    "                 'juil.' : 7\n",
    "                }\n",
    "    d = date_string.split(' ')[0]  # récupère la date en début de string : 2xxx-MM-DD\n",
    "    d = d.split('-')  # récupère year, month, day\n",
    "    \n",
    "    # print(d)\n",
    "    \n",
    "    try:\n",
    "        day = int(d[0])\n",
    "    except ValueError:\n",
    "        raise NameError('problème de format dans un champ date (jour)')\n",
    "        \n",
    "    try:\n",
    "        year = 2000 + int(d[2])\n",
    "    except ValueError:\n",
    "        raise NameError('problème de format dans un champ date (année)')\n",
    "    \n",
    "    try:\n",
    "        month = int(d[1])\n",
    "    except ValueError:\n",
    "        try:\n",
    "            month = dict_mois.get(d[1])\n",
    "        except ValueError:\n",
    "            raise NameError('problème de format dans un champ date (mois)')\n",
    "        \n",
    "    date_object = datetime.date(year, month, day)\n",
    "    \n",
    "    return date_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd9c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_to_date_num(date_string : str) -> datetime.date:\n",
    "    \"\"\"\n",
    "    fonction qui convertit les string sorties de l'extraction en date,\n",
    "    au format \"YYYY-MM-DD\",\n",
    "    retourne un objet date de la library datetime.\n",
    "    \n",
    "    Permet de faire des calculs sur les dates ensuite.\n",
    "    \"\"\"\n",
    "    \n",
    "    d = date_string.split(' ')[0]  # récupère la date en début de string : 2xxx-MM-DD\n",
    "    d = d.split('-')  # récupère year, month, day\n",
    "    \n",
    "    # print(d)\n",
    "    \n",
    "    try:\n",
    "        day = int(d[2])\n",
    "    except ValueError:\n",
    "        raise NameError('problème de format dans un champ date (jour)')\n",
    "        \n",
    "    try:\n",
    "        year = int(d[0])\n",
    "    except ValueError:\n",
    "        raise NameError('problème de format dans un champ date (année)')\n",
    "    \n",
    "    try:\n",
    "        month = int(d[1])\n",
    "    except ValueError:\n",
    "        raise NameError('problème de format dans un champ date (mois)')\n",
    "        \n",
    "    date_object = datetime.date(year, month, day)\n",
    "    \n",
    "    return date_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaad118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_to_float(float_string:str) -> float:\n",
    "    \"\"\"\n",
    "    conversion basique+ en float.\n",
    "    \n",
    "    renvoie 0 si string vide ou remplie d'espaces, ou string = '-'.\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(float_string) is None:\n",
    "        return 0\n",
    "    \n",
    "    float_string = float_string.replace(\" \",\"\")\n",
    "    if not float_string:\n",
    "        return 0\n",
    "    if float_string == \"-\":\n",
    "        return 0\n",
    "    \n",
    "    try:\n",
    "        float_string = float_string.replace(\" \",\"\")\n",
    "        valeur = float(float_string.replace(',','.'))\n",
    "    except ValueError:\n",
    "        raise NameError('une tentative de conversion en float a échouée car string non compatible')\n",
    "        \n",
    "    return valeur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1b64a1",
   "metadata": {},
   "source": [
    "\n",
    "# 1- Analyse de $E(Y|X=x)$ et $Var(Y|X=x)$ à partir du fichier complet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe4ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construit la liste des dates uniques dans data_brute\n",
    "\n",
    "CUT_OFF_DATE = datetime.date(2020,8,1)  # on ne prend les valeurs qu'à partir du 1er Août 2020 !\n",
    "\n",
    "liste_dates = [ conv_to_date_num(current_dict.get('date')) for current_dict in data_brute if conv_to_date_num(current_dict.get('date')) >= CUT_OFF_DATE ]\n",
    "liste_dates = list(sorted(set(liste_dates)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567876af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construit les dictionnaires des valeurs de MT et MG :\n",
    "# - keys = valeur de datetime.date (date object)\n",
    "# - values = liste des valeurs (float) du jour\n",
    "\n",
    "dict_mt = dict( (d, []) for d in liste_dates )  # initialise le dict MT avec des listes vides des valeurs du jour\n",
    "dict_mg = dict( (d, []) for d in liste_dates )  # idem pour MG\n",
    "\n",
    "for element in data_brute:\n",
    "    if conv_to_date_num(element.get('date')) >= CUT_OFF_DATE:  # nettoyage des data : on ne prend qu'après le cut_off_date\n",
    "        date_object = conv_to_date_num(element.get('date'))\n",
    "        mt = conv_to_float(element.get('MT'))\n",
    "        dict_mt[date_object].append(mt)\n",
    "        mg = conv_to_float(element.get('MG'))\n",
    "        dict_mg[date_object].append(mg)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab8f476",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936a9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construit les dictionnaires d'écart type pour MT et MG\n",
    "# - keys = valeur de datetime.date (date object)\n",
    "# - values = écart-type (float) si calculé > 0\n",
    "\n",
    "std_mt = dict( (d, np.std(vals)) for d,vals in dict_mt.items() if np.std(vals)>0 )\n",
    "std_mg = dict( (d, np.std(vals)) for d,vals in dict_mg.items() if np.std(vals)>0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_mt_for_bplot = [ v for v in std_mt.values() ]\n",
    "std_mg_for_bplot = [ v for v in std_mg.values() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baed688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 8))\n",
    "\n",
    "ax[0].boxplot(std_mt_for_bplot, notch=True)\n",
    "ax[0].set_title('Ecart type Masse Totale')\n",
    "ax[1].boxplot(std_mg_for_bplot, notch=True)\n",
    "ax[1].set_title('Ecart type Masse Grasse')\n",
    "plt.show()\n",
    "\n",
    "PREC = 3\n",
    "\n",
    "print(f'Mediane StdDev Masse Totale = {np.around(np.median(std_mt_for_bplot),decimals=PREC)}, \\\n",
    "    Moyenne StdDev Masse Totale = {np.around(np.mean(std_mt_for_bplot), decimals=PREC)}')\n",
    "print(f'Mediane StdDev Masse Grasse = {np.around(np.median(std_mg_for_bplot),decimals=PREC)}, \\\n",
    "    Moyenne StdDev Masse Grasse = {np.around(np.mean(std_mg_for_bplot), decimals=PREC)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f208963",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_std_dev_mg = np.around(np.median(std_mg_for_bplot),decimals=PREC)   # mediane de l'écart-type sur la mesure de la MG\n",
    "last_mt = np.mean(dict_mt.get(list(dict_mt.keys())[-1]))   # moyenne de la dernière valeur de la masse totale mesurée\n",
    "\n",
    "print(f'Intervalle de confiance à 95% sur mesure de body fat% (+/- 2 sigma): +/- {np.around(2*med_std_dev_mg/last_mt*100, decimals=PREC)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86f8ef",
   "metadata": {},
   "source": [
    "# 2- Calcul du body fat% : $E(MG/MT)$ ou $E(MT)/E(MG)$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae8fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul de E(MG/MT) et E(MT) / E(MG)\n",
    "e_mg_mt = []\n",
    "std_dev_mg_mt = []  # là on calcule l'écart type des valeurs de mg/mt du jour\n",
    "e_mg_e_mt = []\n",
    "\n",
    "for mt_data, mg_data in zip(dict_mt.items(), dict_mg.items()):\n",
    "    # vérifie qu'on est bien sur la même date !\n",
    "    if mt_data[0] != mg_data[0]:\n",
    "        NameError('dates différentes dans dict_mt et dict_mg, impossible calculer MG/MT du jour')\n",
    "    mt = np.array(mt_data[1])\n",
    "    mg = np.array(mg_data[1])\n",
    "    \n",
    "    # vérifie qu'il y a bien le même nombre de valeurs dans la journée\n",
    "    if len(mt) != len(mg):\n",
    "        NameError('nombre de valeurs différentes dans une même journée dans dict_mt et dict_mg')\n",
    "        \n",
    "    if np.sum(np.abs(mg)) > 0 and np.sum(np.abs(mt)) > 0:\n",
    "        e_mg_mt.append(np.mean(mg/mt))\n",
    "        std_dev_mg_mt.append(np.std(mg/mt))  # calcule l'écart type de la liste des calculs mg/mt du jour\n",
    "        e_mg_e_mt.append(np.mean(mg)/np.mean(mt))\n",
    "        \n",
    "e_mg_mt = np.array(e_mg_mt)\n",
    "e_mg_e_mt = np.array(e_mg_e_mt)\n",
    "std_dev_mg_mt = np.array(std_dev_mg_mt)\n",
    "\n",
    "diff = np.abs(e_mg_mt - e_mg_e_mt)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b4b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3,ax4) = plt.subplots(nrows = 1, ncols = 4, figsize=(24,8) )\n",
    "\n",
    "ax1.plot(e_mg_mt)\n",
    "ax1.grid()\n",
    "ax1.set_title('Body Fat calcul 1 : Moyenne de (MG sur MT)')\n",
    "\n",
    "ax2.plot(e_mg_e_mt)\n",
    "ax2.grid()\n",
    "ax2.set_title('Body Fat calcul 2 : Moyenne de MG sur Moyenne de MT')\n",
    "\n",
    "ax3.plot(diff)\n",
    "ax3.grid()\n",
    "ax3.set_title('Ecart entre E(MG/MT) et E(MG)/E(MT)')\n",
    "\n",
    "ax4.plot(std_dev_mg_mt * 100)\n",
    "ax4.grid()\n",
    "ax4.set_title('Ecart type des valeurs MG/MT du jour, en %')\n",
    "\n",
    "print(f'Erreur maximale commise entre E(MT/MG) et E(MT)/E(MG) = {np.around(max(diff), decimals=8)}')\n",
    "\n",
    "print(f'Moyenne Ecart type de la mesure de masse grasse (en %, comparable à la valeur MG/MT) : {np.around(np.mean(std_dev_mg_mt * 100), 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f07633",
   "metadata": {},
   "source": [
    "# 2- Collection des données de calories, calcul MG%, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3786d",
   "metadata": {},
   "source": [
    "### On commence par créer un numpy array avec toutes les datas :\n",
    "- date ordinale (convertie des datetime objects)\n",
    "- masse totale\n",
    "- masse grasse\n",
    "- pourcentage de masse grasse (si masse totale et masse grasse > 0)\n",
    "- calories ingérées\n",
    "- proteines\n",
    "- glucides\n",
    "- lipides\n",
    "- calories exercice (éventuellement 0)\n",
    "- calories cardio (éventuellement 0)\n",
    "- calories muscu (éventuellement 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2081dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "keys = list(poids_cal_exos[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today()\n",
    "\n",
    "for d in poids_cal_exos:\n",
    "    \n",
    "    date_d = conv_to_date_str(d.get('date'))\n",
    "    \n",
    "    if date_d <= today:\n",
    "        X_day =[ conv_to_float(d.get(k)) if k != 'date' else date_d for k in keys ]\n",
    "        \n",
    "        mt = conv_to_float(d.get('Masse Totale'))\n",
    "        mg = conv_to_float(d.get('Masse Grasse'))\n",
    "        if mt>0 and mg>0:\n",
    "            bf = mg/mt\n",
    "        else:\n",
    "            bf = 0.0\n",
    "            \n",
    "        X_day.append(bf)  # rajoute body fat% en dernière valeur\n",
    "        # print(X_day)\n",
    "        X.append(X_day)\n",
    "        \n",
    "keys.append('Body Fat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f5049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3814701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704d8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on rajoute la date ordinale en avant-dernière colonne\n",
    "keys[keys.index('Verif')]='date_ordinale'\n",
    "X[:,keys.index('date_ordinale')] = [x.toordinal() for x in X[:,keys.index('date')] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3e301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d896f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(X)} data depuis {CUT_OFF_DATE} jusqu\"à {today}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040be493",
   "metadata": {},
   "source": [
    "# 3- Affichage basique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_plot(dates, y, \n",
    "               grid=True,\n",
    "               title='titre', perc=False,\n",
    "               moyenne_glissante=False, n_moy=7, \n",
    "               reg_lineaire=False, n_reg=30):\n",
    "    \n",
    "    \"\"\"Affiche y suivant les dates, avec grid ou pas, avec moyenne glissante et régression linéaire ou pas.\n",
    "\n",
    "    Args:\n",
    "        dates ([datetime objects]): [dates au format datetime]\n",
    "        y ([float]): [la valeur à afficher]\n",
    "        grid (bool, optional): [présence ou pas de la grille]. Defaults to True.\n",
    "        title(string, optional): [titre]. Defaults to 'titre'\n",
    "        moyenne_glissante (bool, optional): [affiche ou pas la moyenne glissante]. Defaults to False.\n",
    "        nj_moyenne (int, optional): [fenêtre de calcul de la moyenne glissante]. Defaults to 7.\n",
    "        reg_lineaire (bool, optional): [affiche ou pas la régression linéaire]. Defaults to False.\n",
    "        nj_regression (int, optional): [fenêtre de calcul de la régression linéaire]. Defaults to 30.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(16,8))\n",
    "    ax1.plot(dates, y, color='blue', marker='x')\n",
    "    ax1.set_title(title)\n",
    "    \n",
    "    if grid: \n",
    "        ax1.grid()\n",
    "    \n",
    "    if moyenne_glissante:\n",
    "        # plot moyenne glissante sur les n_moy dernières valeurs\n",
    "        moy = np.zeros(shape=len(y))\n",
    "        moy[0] = y[0]\n",
    "        for i in range(1,len(y)):\n",
    "            id = max(0, i-n_moy+1)\n",
    "            moy[i] = np.mean(y[id:i])\n",
    "        ax1.plot(dates, moy, color='red', marker='o')\n",
    "    \n",
    "    if reg_lineaire:\n",
    "        # plot regression linéaire sur les n_reg dernières valeurs de y\n",
    "        dates_ordinales = np.array([ d.toordinal() for d in dates]).reshape(-1,1)\n",
    "        lr_model = LinearRegression().fit(dates_ordinales[-n_reg:], y[-n_reg:])   # fit sur les n_reg dernières valeurs\n",
    "        reg_pred = lr_model.predict(dates_ordinales)\n",
    "        ax1.plot(dates, reg_pred, color='green', marker='+')\n",
    "        pente =lr_model.coef_[0] * 30 # coefficient par mois\n",
    "        if perc==True: pente *= 100\n",
    "        coeff = lr_model.score(dates_ordinales[-n_reg:], y[-n_reg:])\n",
    "        ax2.text(0.1,0.8,f'régression calculée de {dates[-n_reg]} à {dates[-1]}')\n",
    "        if perc==True:\n",
    "            str_pente = f'pente = {np.around(pente, decimals=PREC)}% / mois'\n",
    "        else:\n",
    "            str_pente = f'pente = {np.around(pente, decimals=PREC)} / mois'\n",
    "        ax2.text(0.1,0.7,str_pente)\n",
    "        ax2.text(0.1,0.6,f'coefficient régression = {np.around(coeff * 100,1)}%')\n",
    "        \n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0265ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupère les data entre deux dates\n",
    "\n",
    "start_date = datetime.date(2021,8,1)\n",
    "start_date_index = list(X[:,0]).index(start_date)\n",
    "\n",
    "end_date = datetime.date(2021,9,30)\n",
    "end_date_index = list(X[:,0]).index(end_date)\n",
    "\n",
    "X_trim = X[start_date_index:end_date_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e96774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5836ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# affiche certaines data depuis cette start date\n",
    "\n",
    "data_of_interest = ['Masse Totale', 'Masse Grasse', 'Calories in', 'Body Fat']\n",
    "idx = [ keys.index(l) for l in data_of_interest ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19ca1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [ el[0] for el in X_trim]\n",
    "for id, l in zip(idx, data_of_interest):\n",
    "    y = [el[id] for el in X_trim ]\n",
    "    f = basic_plot(dates, y, grid=True, perc=(l=='Body Fat'), moyenne_glissante=True, reg_lineaire=True, title=l)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daec735",
   "metadata": {},
   "source": [
    "# 4 - Heatmap corrélations\n",
    "\n",
    "https://heartbeat.fritz.ai/seaborn-heatmaps-13-ways-to-customize-correlation-matrix-visualizations-f1c49c816f07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dea9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2021,1,1)   # depuis le 1er Janvier 2021\n",
    "start_date_index = list(X[:,0]).index(start_date)\n",
    "\n",
    "end_date = datetime.date(2021,9,20)  # <== A CHANGER ICI\n",
    "end_date_index = list(X[:,0]).index(end_date)\n",
    "\n",
    "X_trim = X[start_date_index:end_date_index,1:]\n",
    "df = pd.DataFrame(X_trim, columns=keys[1:]).astype(float)   # on créé une dataframe avec tous les floats (exclus les datetime.objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd31ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056420b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb996196",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a1c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4cb52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "sns.heatmap(df.corr(), \n",
    "            annot=True, \n",
    "            fmt='.2g',\n",
    "            vmin=-1, vmax=1, center=0,\n",
    "            cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c212211",
   "metadata": {},
   "source": [
    "## Commentaires sur le body fat% :\n",
    "- corrélations évidentes du bf% avec Masse Totale, Masse Grasse, et Date\n",
    "- corrélations avec Protéines (-.49), Lipides (0.28), C_ex_cardio (.19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf99cd8b",
   "metadata": {},
   "source": [
    "# Le temps des prévisions\n",
    "\n",
    "On va chercher Masse_Totale(j+1), Masse_Grasse(j+1) = f(Masse_Totale(j), Masse_Grasse(j), C_in(j), Glu(j), Lip(j), Pro(j), C_cardio(j), C_strength(j))\n",
    "\n",
    "Variables d'intérêt : on va chercher à prédire la **Masse Totale** et la **Masse Grasse**.\n",
    "\n",
    "Les modèles sont donc des modèles de régression, avec une sortie y à deux dimensions.\n",
    "\n",
    "La loss utilisée sur les vecteurs 2D sera la **norme 1** (mean absolute error), avec un poids différent entre la première coordonnée (qui varie typiquement entre 108 et 68kg sur le dataset), et la deuxième coordonnée (qui varie entre .33 et .12)\n",
    "\n",
    "Les modèles regardés seront :\n",
    "- prédiction näive (prédiction à J+1 = valeur de la veille)\n",
    "- régression linéaire (NB : on cherchera la fenêtre temporelle pertinente, cad quels sont les N dernières valeurs à considérer pour avoir un bon niveau de précision)\n",
    "- MLP\n",
    "- LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490f533",
   "metadata": {},
   "source": [
    "### Creation du dataset\n",
    "\n",
    "On prend le X en entrée, et on construit un tf.Dataset avec comme y_true les valeurs de Masse Totale et Masse Grasse du jour suivant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf45d585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, \n",
    "                   start_date = datetime.date(2020,8,1), \n",
    "                   end_date = datetime.date.today()-datetime.timedelta(days=1),\n",
    "                   # keys = ['date', 'Masse Totale', 'Masse Grasse', 'Calories in', 'Glucides', 'Lipides', 'Proteines', 'Calories Exercice Brut', 'C_Ex_Cardio', 'C_Ex_Strength', 'date_ordinale', 'Body Fat']\n",
    "                   keys_to_keep = ['Masse Totale', 'Masse Grasse', 'Calories in', 'Glucides', 'Lipides', 'Proteines', 'C_Ex_Cardio', 'C_Ex_Strength']\n",
    "                   ):\n",
    "\n",
    "    \"\"\"Construit et retourne un tf.dataset, à partir du fichier de données, entre les dates fournies\n",
    "\n",
    "    Args:\n",
    "        X ([np.array]): [c'est le tableau de données journalières :\n",
    "        keys ([list]) : la liste des champs, defaults to ['Masse Totale', 'Masse Grasse', 'Calories in', 'Glucides', 'Lipides', 'Proteines', 'C_Ex_Cardio', 'C_Ex_Strength'] ]\n",
    "        start_date ([datetime object], optional): [description]. Defaults to datetime.date(2020,8,1).\n",
    "        end_date ([datetime objectf], optional): [description]. Defaults to datetime.today()-1.\n",
    "\n",
    "    Returns : tf.Data.dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    start_date_index = list(X[:,0]).index(start_date)\n",
    "    end_date_index = list(X[:,0]).index(end_date)\n",
    "    \n",
    "    index_mt = keys.index('Masse Totale')\n",
    "    index_mg = keys.index('Masse Grasse')\n",
    "    \n",
    "    idx_to_keep = [ keys.index(k) for k in keys_to_keep ]\n",
    "                       \n",
    "    X_trim = np.array(X[start_date_index:end_date_index-1,idx_to_keep],dtype=float)  # on ne prend pas la date sous format object, et on s'arrête à l'avant-dernière valeur\n",
    "    \n",
    "    y = np.array([ [X[i+1][index_mt],X[i+1][index_mg]] for i in range(start_date_index, end_date_index-1)], dtype=float)\n",
    "    \n",
    "    print(X_trim.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    return tf.data.Dataset.from_tensor_slices((X_trim, y))\n",
    "    \n",
    "    # return tf.data.Dataset.from_tensor_slices([X_trim, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7ac1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2020,9,1) \n",
    "end_date = datetime.date.today()-datetime.timedelta(days=1)\n",
    "\n",
    "ds = create_dataset(X, start_date = start_date, end_date=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182ccbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f81a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in ds.take(3):\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e3799a",
   "metadata": {},
   "source": [
    "# Naive Forecasting\n",
    "\n",
    "Ici, le modèle prédit pour le jour suivant, la valeur du jour : cela servira de baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b28d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2020,9,1) \n",
    "end_date = datetime.date.today()-datetime.timedelta(days=1)\n",
    "\n",
    "ds = create_dataset(X, start_date = start_date, end_date=end_date)\n",
    "\n",
    "index_mt = 0\n",
    "index_mg = 1\n",
    " \n",
    "y_true = np.array([ el[1] for el in ds ], dtype = float )\n",
    "y_pred = np.array([ [el[0][index_mt], el[0][index_mg]] for el in ds], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea01ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77aebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50523e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa0b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2550c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4248fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_results(y_pred, y_true,\n",
    "                   history = None,\n",
    "                   start_date = datetime.date(2020,9,1),\n",
    "                   end_date = datetime.date.today() - datetime.timedelta(days=1),\n",
    "                   ):\n",
    "    \n",
    "    x = [ start_date + datetime.timedelta(days=i) for i in range(end_date.toordinal() - start_date.toordinal() - 1)]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(32,12))\n",
    "\n",
    "    ax[0][0].set_title(\"prediction masse totale\")\n",
    "    ax[0][0].plot(x, y_true[:,0], marker = 'x', label='true')\n",
    "    ax[0][0].plot(x, y_pred[:,0], marker = '.', label='pred')\n",
    "    ax[0][0].legend()\n",
    "    ax[0][0].grid()\n",
    "\n",
    "    ax[1][0].set_title(\"prediction masse grasse\")\n",
    "    ax[1][0].plot(x, y_true[:,1], marker = 'x', label='true')\n",
    "    ax[1][0].plot(x, y_pred[:,1], marker = '.', label='pred')\n",
    "    ax[1][0].legend()\n",
    "    ax[1][0].grid()\n",
    "\n",
    "    mae_mt = np.array( [np.abs([y[0][0] - y[1][0]]) for y in zip (y_true, y_pred) ] )\n",
    "    mae_mt_moyenne = np.full( shape=len(mae_mt), fill_value = mae_mt.mean() )\n",
    "\n",
    "    ax[0][1].set_title(\"erreur norme 1 prediction masse totale\")\n",
    "    ax[0][1].plot(x, mae_mt, marker = 'x')\n",
    "    ax[0][1].plot(x, mae_mt_moyenne, marker = '.', label = 'moyenne')\n",
    "    ax[0][1].legend()\n",
    "    ax[0][1].grid()\n",
    "\n",
    "    mae_mg = np.array( [np.abs([y[0][1] - y[1][1]]) for y in zip (y_true, y_pred) ] )\n",
    "    mae_mg_moyenne = np.full( shape=len(mae_mg), fill_value = mae_mg.mean() )\n",
    "\n",
    "    ax[1][1].set_title(\"erreur norme 1 prediction masse grasse\")\n",
    "    ax[1][1].plot(x, mae_mg, marker = 'x')\n",
    "    ax[1][1].plot(x, mae_mg_moyenne, marker = '.', label = 'moyenne')\n",
    "    ax[1][1].legend()\n",
    "    ax[1][1].grid()\n",
    "    \n",
    "    if history:\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (8,8))\n",
    "        erreur = list(history.history.keys())[-1]\n",
    "        values = history.history.get(erreur)\n",
    "        ax.plot(values)\n",
    "        ax.grid()\n",
    "        norm_1 = np.array(values).mean()\n",
    "        ax.set_title(erreur + ' vs Epoch')\n",
    "        print(erreur + f' cumulée MT et MG sur validation set: {np.around(norm_1, decimals=3)} kg')\n",
    "        \n",
    "    window_last_days = 30\n",
    "    \n",
    "    print(f'Erreur moyenne norme 1 sur MT sur les {window_last_days} derniers jours : {np.around(mae_mt[-window_last_days:].mean(), decimals=3)} kg')\n",
    "    print(f'Erreur moyenne norme 1 sur MG sur les {window_last_days} derniers jours : {np.around(mae_mg[-window_last_days:].mean(), decimals=3)} kg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0bcdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_results(y_pred, y_true, start_date=start_date, end_date=end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0176efc0",
   "metadata": {},
   "source": [
    "# Basic MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d05c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mae(y_pred, y_true):\n",
    "    \"\"\"Custom loss pour prendre en compte le delta entre MT et MG\n",
    "\n",
    "    Args:\n",
    "        y_pred ([float]): prédictions, (batch_size, 2)\n",
    "        y_true ([float]): ground truth, (batch_size, 2)\n",
    "        \n",
    "    Returns : float\n",
    "    \"\"\"\n",
    "    # calculating squared difference between target and predicted values \n",
    "    loss = tf.keras.backend.abs(y_pred - y_true)  # (batch_size, 2)\n",
    "    \n",
    "    # multiplying the values with weights along batch dimension\n",
    "    loss = loss * [0.1, 0.9]          # (batch_size, 2)\n",
    "                \n",
    "    # summing both loss values along batch dimension \n",
    "    loss = tf.keras.backend.sum(loss, axis=1)        # (batch_size,)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efded81",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2020,9,1) \n",
    "end_date = datetime.date.today()-datetime.timedelta(days=1)\n",
    "\n",
    "ds = create_dataset(X, start_date = start_date, end_date=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca9c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(ds)\n",
    "SPLIT_RATIO = 0.9\n",
    "train_size = int(total_size * SPLIT_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d920aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds.take(train_size).batch(1)  # NB : le .batch() est nécessaire... pourquoi ?\n",
    "ds_val = ds.skip(train_size).batch(1)  # NB : on valide sur les derniers xx %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a885a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(units=64, activation='relu', name='couche_MLP_1', input_shape=([8])),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu', name='couche_MLP_2'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu', name='couche_MLP_3'),\n",
    "    tf.keras.layers.Dense(units=2,\n",
    "                          name='output',\n",
    "                          ),\n",
    "    # tf.keras.layers.Reshape((2,1))\n",
    "], name = 'basic_MLP')\n",
    "\n",
    "tf.keras.utils.plot_model(model_lr,\n",
    "                          show_shapes=True,\n",
    "                          show_dtype=True,\n",
    "                          show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df610de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'mae',\n",
    "    metrics = ['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f32d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience = 10,\n",
    "    min_delta = 0,\n",
    "    restore_best_weights=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b1bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_lr.fit(\n",
    "    ds_train,\n",
    "    epochs = 1000,\n",
    "    callbacks=[cb],\n",
    "    validation_data=ds_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c25f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([ el[1] for el in ds ], dtype = float )\n",
    "# y_pred = np.array([ [el[0][index_mt], el[0][index_bf]] for el in ds], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852dcc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_total = ds.batch(1)\n",
    "y_pred = model_lr.predict(ds_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(history.history.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_results(y_pred, y_true, history=history, start_date=start_date, end_date=end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e71bbaa",
   "metadata": {},
   "source": [
    "# Approche par time-series\n",
    "\n",
    "La prédiction au jour J du vecteur (masse totale, masse grasse), dépend de l'historique des données journalières sur une certaine période (à définir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966af9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13299feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8416ab8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6918068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b49cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80895f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bc6075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f5673a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b7e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a88cae013bc266f91956c621ac2a9dfee8dd2d162739bef9a31579bbafa5253b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
